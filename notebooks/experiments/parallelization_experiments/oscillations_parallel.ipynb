{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d563a4b6",
   "metadata": {},
   "source": [
    "# Oscillation\n",
    "This notebook contains experiments comparing methods for detecting oscillations. Using historical data, we simulate the following real-time detection scenario: streams of voltage/current measurements are retrieved, and we need to decide in (near) real-time whether an oscillation is beginning to occur. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9bb707",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "module_path = os.path.abspath(os.path.join('../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from modules.preprocessing import *\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "from timeit import default_timer as timer\n",
    "from sklearn.ensemble import RandomForestRegressor as RFRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "import lightgbm as lgb\n",
    "plt.style.use('ggplot')\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import glob\n",
    "import datetime\n",
    "import math as mt\n",
    "import scipy.linalg as sl\n",
    "import scipy.optimize as opt\n",
    "import time\n",
    "from glob import glob\n",
    "from os_utils import * "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a269d67",
   "metadata": {},
   "source": [
    "# Test the performance of ocsillation method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c01ca9c",
   "metadata": {},
   "source": [
    "## Import Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca2a95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "from dask.distributed import wait\n",
    "import dask\n",
    "from dask import delayed\n",
    "dask.config.set(scheduler='synchronous')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bfcec9",
   "metadata": {},
   "source": [
    "## Start Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5fb160",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 30\n",
    "client = Client(n_workers=num_workers,threads_per_worker=1)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9b5bed",
   "metadata": {},
   "source": [
    "## Create streams in memory for the experimental evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292deccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read once, create many copies\n",
    "\n",
    "f = '/data/data2/oscillations_data/synthetic/large_os_data.csv'\n",
    "#read 100000\n",
    "df = pd.read_csv(f, nrows = 100000)\n",
    "df = df.set_index('timestamp')\n",
    "df.index = pd.to_datetime(df.index)\n",
    "### this window size corresponds to 10 s\n",
    "\n",
    "temp_stream = df.values\n",
    "\n",
    "n_streams = 60000\n",
    "\n",
    "test_data = np.tile([temp_stream], (n_streams, 1, 1))\n",
    "for j in range(len(test_data)):\n",
    "    for i in range(test_data.shape[2]):\n",
    "        noise =  np.random.normal(0, 0.1, test_data.shape[1])\n",
    "        test_data[j, :, i] = test_data[j, :, i] + noise\n",
    "             \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41fb2ba",
   "metadata": {},
   "source": [
    "## Sequential execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15813ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_sin_simple2(y, step):\n",
    "    \"\"\"\n",
    "    Estimate a signal using an FFT-based method.\n",
    "\n",
    "    Parameters:\n",
    "        df (array-like): The input signal to estimate.\n",
    "        \n",
    "\n",
    "    Returns:\n",
    "        A tuple (data_fit, y_norm) containing the estimated (normalized) signal and the normalized signal.\n",
    "    \"\"\"\n",
    "    #index = (df.index - min(df.index)).total_seconds()\n",
    "    index = np.array(range(len(y)))/step\n",
    "    var = np.var(y)\n",
    "    # Normalized data\n",
    "    y_norm = (y - np.mean(y))/var\n",
    "    acorr = sm.tsa.acf(y_norm, nlags = len(y_norm)-1)\n",
    "    peaks = signal.find_peaks(acorr[:len(y_norm)])\n",
    "    try:\n",
    "        peak_idx = peaks[0][0]\n",
    "        #est_freq = 1/(df.index[peak_idx]-df.index[0]).total_seconds()\n",
    "        est_freq = 1/((peak_idx+1)/step)\n",
    "    except:\n",
    "        est_freq = 1\n",
    "    \n",
    "    #find amplitude\n",
    "    #optimize_func = lambda x: (x[0]*np.sin(2*np.pi*index) - y_norm)\n",
    "    #find phase\n",
    "    yf = np.fft.fft(y_norm)\n",
    "    T = 1/30\n",
    "    freq = np.fft.fftfreq(y.size, d=T)\n",
    "    ind, = np.where(np.isclose(freq, est_freq, atol=1/(T*len(y))))\n",
    "    est_phase = np.angle(yf[ind[0]])\n",
    "    est_amp = np.sqrt(2)*np.std(y_norm)\n",
    "    #index =\n",
    "    data_fit = est_amp*np.sin(2*np.pi*est_freq*index+est_phase) \n",
    "    return data_fit, y_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ec02fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#sequential\n",
    "\n",
    "running_time = []\n",
    "total_running_time = 0.0\n",
    "\n",
    "window_size = 1000\n",
    "step = 30\n",
    "M = len(test_data[0])\n",
    "j = 0\n",
    "while j < M:  \n",
    "    for i, arr in enumerate(test_data):\n",
    "        y = arr[j:min(j+window_size, M)]\n",
    "        \n",
    "        # Approximate the signal using a simple fft-based sinusoidal regression\n",
    "        start = time.time()\n",
    "        approx_signal4, y_norm = fit_sin_simple2(y, step)\n",
    "        end = time.time()\n",
    "        \n",
    "        running_time_temp = end - start\n",
    "        running_time.append(running_time_temp)\n",
    "        total_running_time = total_running_time + running_time_temp\n",
    "    j = j + window_size\n",
    "print (\"total_running_time = \", total_running_time )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ff74f3",
   "metadata": {},
   "source": [
    "## Parallel Batch code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dc8ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_sin_simple2(y, step):\n",
    "    \"\"\"\n",
    "    Estimate a signal using an FFT-based method.\n",
    "\n",
    "    Parameters:\n",
    "        df (array-like): The input signal to estimate.\n",
    "        \n",
    "\n",
    "    Returns:\n",
    "        A tuple (data_fit, y_norm) containing the estimated (normalized) signal and the normalized signal.\n",
    "    \"\"\"\n",
    "    #index = (df.index - min(df.index)).total_seconds()\n",
    "    index = np.array(range(len(y)))/step\n",
    "    var = np.var(y)\n",
    "    # Normalized data\n",
    "    y_norm = (y - np.mean(y))/var\n",
    "    acorr = sm.tsa.acf(y_norm, nlags = len(y_norm)-1)\n",
    "    peaks = signal.find_peaks(acorr[:len(y_norm)])\n",
    "    try:\n",
    "        peak_idx = peaks[0][0]\n",
    "        #est_freq = 1/(df.index[peak_idx]-df.index[0]).total_seconds()\n",
    "        est_freq = 1/((peak_idx+1)/step)\n",
    "    except:\n",
    "        est_freq = 1\n",
    "    \n",
    "    #find amplitude\n",
    "    #optimize_func = lambda x: (x[0]*np.sin(2*np.pi*index) - y_norm)\n",
    "    #find phase\n",
    "    yf = np.fft.fft(y_norm)\n",
    "    T = 1/30\n",
    "    freq = np.fft.fftfreq(y.size, d=T)\n",
    "    ind, = np.where(np.isclose(freq, est_freq, atol=1/(T*len(y))))\n",
    "    est_phase = np.angle(yf[ind[0]])\n",
    "    est_amp = np.sqrt(2)*np.std(y_norm)\n",
    "    #index =\n",
    "    data_fit = est_amp*np.sin(2*np.pi*est_freq*index+est_phase) \n",
    "    return data_fit, y_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af4e323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oscillations_predict(batch_data, step):\n",
    "    results = []\n",
    "    for batch in batch_data:\n",
    "        approx_signal4, y_norm = fit_sin_simple2(batch, step)\n",
    "        results.append(pprox_signal4, y_norm)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40337b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_batch_processing_delayed(batch_data, step):\n",
    "    running_time = 0.0\n",
    "    futures = []\n",
    "    \n",
    "    delayed_process = dask.delayed(oscillations_predict)\n",
    "    \n",
    "    delayed_results = [delayed_process(arr,step) for arr in batch_data]\n",
    "    \n",
    "    start = time.time()\n",
    "    results = dask.compute(*delayed_results)  \n",
    "    end = time.time()\n",
    "    \n",
    "    del futures\n",
    "    del results\n",
    "    \n",
    "    running_time = end - start\n",
    "    \n",
    "    return running_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89e8647",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#parallel\n",
    "\n",
    "batch_data_size = len(test_data)//num_workers\n",
    "batch_data = []\n",
    "batch_data_all = []\n",
    "counter = 0;\n",
    "num_worker = 0\n",
    "\n",
    "running_time = []\n",
    "total_running_time = 0.0\n",
    "\n",
    "window_size = 100\n",
    "step = 30\n",
    "M = len(test_data[0])\n",
    "j = 0\n",
    "while j < M:    \n",
    "    for i, arr in enumerate(test_data):\n",
    "\n",
    "        y = arr[j:min(j+window_size, M)]\n",
    "       \n",
    "        if (counter < batch_data_size):\n",
    "            batch_data.append(y)\n",
    "            counter = counter + 1\n",
    "        elif num_worker == num_workers - 1:\n",
    "            batch_data.append(y)\n",
    "        else:\n",
    "            counter = 0\n",
    "            batch_data_all.append(batch_data)\n",
    "            \n",
    "            batch_data = []\n",
    "            batch_data.append(y)\n",
    "            counter = counter + 1\n",
    "            num_worker = num_worker + 1\n",
    "     \n",
    "    batch_data_all.append(batch_data)\n",
    "    batch_data = []\n",
    "    \n",
    "    num_worker = 0\n",
    "    counter = 0\n",
    "    \n",
    "    running_time_temp = parallel_batch_processing_delayed(batch_data_all, step)\n",
    "    running_time.append(running_time_temp)\n",
    "    total_running_time = total_running_time + running_time_temp\n",
    "    batch_data_all = []\n",
    "    \n",
    "    j = j + window_size\n",
    "print (\"total_running_time = \", total_running_time )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da89926",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe24b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_streams = 60000, window_size = 100:\n",
    "    \n",
    "    sequential:\n",
    "        total_running_time =  9792.758454322815\n",
    "        CPU times: user 2h 44min 49s, sys: 10.1 s, total: 2h 44min 59s\n",
    "        Wall time: 2h 45min 3s\n",
    "            \n",
    "    threads = 5:\n",
    "        total_running_time =  2535.8568437099457\n",
    "        CPU times: user 11min 23s, sys: 2min 5s, total: 13min 29s\n",
    "        Wall time: 45min 59s \n",
    "            \n",
    "    threads = 8:\n",
    "        total_running_time =  1771.6430671215057\n",
    "        CPU times: user 10min 12s, sys: 2min 15s, total: 12min 27s\n",
    "        sWall time: 32min 26s\n",
    "            \n",
    "    threads = 10:\n",
    "        total_running_time =  1507.3006780147552\n",
    "        CPU times: user 10min 45s, sys: 1min 35s, total: 12min 21s\n",
    "        Wall time: 28min 13s\n",
    "    \n",
    "    threads = 15:\n",
    "        total_running_time =  1141.111942768097\n",
    "        CPU times: user 9min 14s, sys: 1min 46s, total: 11min 1s\n",
    "        Wall time: 22min\n",
    "        \n",
    "    threads = 16:\n",
    "        total_running_time =  1110.9579532146454\n",
    "        CPU times: user 9min 29s, sys: 2min, total: 11min 30s\n",
    "        Wall time: 20min 51s\n",
    "        \n",
    "    threads = 20:\n",
    "        total_running_time =  984.4872004985809\n",
    "        CPU times: user 9min 33s, sys: 2min 4s, total: 11min 38s\n",
    "        Wall time: 18min 54s\n",
    "            \n",
    "    threads = 30:\n",
    "        total_running_time =  857.7079653739929\n",
    "        CPU times: user 9min 14s, sys: 2min 16s, total: 11min 31s\n",
    "        Wall time: 16min 37s        \n",
    "      \n",
    "    \n",
    "n_streams = 60000, threads = 30 :\n",
    "        \n",
    "    window_size = 40 :\n",
    "        total_running_time =  1858.6870143413544\n",
    "        CPU times: user 21min 47s, sys: 3min 11s, total: 24min 58s\n",
    "        Wall time: 36min 52s\n",
    "            \n",
    "    window_size = 60 :\n",
    "        total_running_time =  1290.3779816627502\n",
    "        CPU times: user 15min 13s, sys: 2min 17s, total: 17min 30s\n",
    "        Wall time: 25min 42s\n",
    "            \n",
    "    window_size = 80 :\n",
    "        total_running_time =  1032.3376879692078\n",
    "        CPU times: user 11min 54s, sys: 2min 11s, total: 14min 6s\n",
    "        Wall time: 20min 22s\n",
    "            \n",
    "    window_size = 100 :\n",
    "        total_running_time =  857.7079653739929\n",
    "        CPU times: user 9min 14s, sys: 2min 16s, total: 11min 31s\n",
    "        Wall time: 16min 37s  \n",
    "            \n",
    "    window_size = 120 :\n",
    "        total_running_time =  731.5465259552002\n",
    "        CPU times: user 8min 15s, sys: 1min 47s, total: 10min 3s\n",
    "        Wall time: 14min 18s\n",
    "        \n",
    "    window_size = 140 :\n",
    "        total_running_time =  667.1877629756927\n",
    "        CPU times: user 7min 16s, sys: 1min 56s, total: 9min 13s\n",
    "        Wall time: 12min 59s\n",
    " \n",
    "\n",
    "threads = 30, window_size = 100: \n",
    "    \n",
    "    n_streams = 20000:\n",
    "        total_running_time =  322.40996408462524\n",
    "        CPU times: user 3min 47s, sys: 34.5 s, total: 4min 21s\n",
    "        Wall time: 6min 11s\n",
    "        \n",
    "    n_streams = 40000:\n",
    "        total_running_time =  585.6359477043152\n",
    "        CPU times: user 6min 46s, sys: 1min 14s, total: 8min 1s\n",
    "        Wall time: 11min 18s\n",
    "        \n",
    "    n_streams = 60000:\n",
    "        total_running_time =  857.7079653739929\n",
    "        CPU times: user 9min 14s, sys: 2min 16s, total: 11min 31s\n",
    "        Wall time: 16min 37s  \n",
    "        \n",
    "    n_streams =80000:\n",
    "        total_running_time =  1145.0851163864136\n",
    "        CPU times: user 12min 48s, sys: 2min 54s, total: 15min 42s\n",
    "        Wall time: 22min 25s\n",
    "        \n",
    "    n_streams =100000:\n",
    "        total_running_time =  1415.4163179397583\n",
    "        CPU times: user 16min 6s, sys: 3min 33s, total: 19min 39s\n",
    "        Wall time: 27min 52s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d46a88",
   "metadata": {},
   "source": [
    "## Close Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa75d75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
