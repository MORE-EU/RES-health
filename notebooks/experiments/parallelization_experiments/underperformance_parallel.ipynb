{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "872b023d",
   "metadata": {},
   "source": [
    "# Underperformance detection\n",
    "\n",
    "In this notebook, we explore a self-supervised approach for the underperformance use-case. Given a time series comprising measurements from a turbine including power output and dependent parameters like wind speed and rotor speed, we i) distinguish between periods of underperformance and periods of optimal performance using an unsupervised method, and ii) we use those periods to train a classifier which can be then tested in new data.\n",
    "\n",
    "To evaluate our approach, we compare our output with the ground-truth information, where we assume that we have underperformance if and only if the static yaw angle (which is provided) is non-zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5407fbd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "module_path = './'\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from modules.preprocessing import *\n",
    "from modules.io import *\n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "from timeit import default_timer as timer\n",
    "from sklearn.ensemble import RandomForestRegressor as RFRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "import lightgbm as lgb\n",
    "plt.style.use('ggplot')\n",
    "from sklearn.linear_model import QuantileRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac225ca",
   "metadata": {},
   "source": [
    "# Test the performance of underperformance method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c525a017",
   "metadata": {},
   "source": [
    "## Import Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dc944f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "from dask.distributed import wait\n",
    "from dask.distributed import as_completed\n",
    "import dask\n",
    "from dask import delayed\n",
    "dask.config.set(scheduler='synchronous')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91894c82",
   "metadata": {},
   "source": [
    "## Start Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47815e3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_workers = 30\n",
    "client = Client(n_workers=num_workers,threads_per_worker=1)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c4361b",
   "metadata": {},
   "source": [
    "## Read filenames of datasets (streams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcead910",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read filenames of datasets (streams)\n",
    "filenames = sorted(glob(os.path.join('/data/data1/synthetic_yaw_data','testing_*.csv')))\n",
    "filenames = filenames[:100] # load 100 for a test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f561f0",
   "metadata": {},
   "source": [
    "## Read datasets (streams) with associated variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e85992",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read datasets (streams) with associated variables\n",
    "target = 'active power'\n",
    "feats = ['active power', 'wind speed',  'rotor speed']\n",
    "test_data = []\n",
    "for f in filenames:\n",
    "    df = load_df(f)\n",
    "    \n",
    "    df = df.set_index('timestamp')\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "    df.columns = df.columns.str.replace('cor. ', '', regex=False)\n",
    "    cols = ['wind speed', 'pitch angle', 'rotor speed', 'active power',\n",
    "            'nacelle direction', 'wind direction']\n",
    "    df = df[cols]\n",
    "\n",
    "    test_data.append(df[feats].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3480a991",
   "metadata": {},
   "source": [
    "## Read pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a68f2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read pretrained model\n",
    "file_path = '/home/ipsarros/pretrained_models/underperformance_classifier2.pickle'\n",
    "with open(file_path, 'rb') as file:\n",
    "    loaded_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf5938e",
   "metadata": {},
   "source": [
    "## Sequential code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb22644",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#sequential\n",
    "\n",
    "\n",
    "window = 1440\n",
    "i = 0\n",
    "running_time = []\n",
    "total_running_time = 0.0\n",
    "\n",
    "\n",
    "while i< len(test_data[0])-window:\n",
    "    \n",
    "    start = time.time()\n",
    "    for arr in test_data:\n",
    "        result = loaded_model.predict(arr[i:i+window],num_threads=1)\n",
    "    end = time.time()\n",
    "    \n",
    "    running_time_temp = end - start\n",
    "    running_time.append(running_time_temp)\n",
    "    total_running_time = total_running_time + running_time_temp  \n",
    "    i = i + window\n",
    "    \n",
    "\n",
    "print (\"total_running_time = \", total_running_time )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d66d54a",
   "metadata": {},
   "source": [
    "## Parallel Batch Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4929cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def underperformance_predict(loaded_model,batch_data):\n",
    "    results = []\n",
    "    for batch in batch_data:\n",
    "        result = loaded_model.predict(batch,num_threads=1)\n",
    "        results.append(result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf72c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_batch_processing_futures(loaded_model, batch_data):\n",
    "    running_time = 0.0\n",
    "    futures = []\n",
    "    \n",
    "    start = time.time()\n",
    "    for batch in batch_data:\n",
    "        future = client.submit(underperformance_predict,loaded_model, batch)\n",
    "        futures.append(future)\n",
    "    wait(futures, return_when=\"ALL_COMPLETED\")\n",
    "    end = time.time()\n",
    "    del futures\n",
    "    futures = []\n",
    "    \n",
    "    running_time = end - start\n",
    "    \n",
    "    return running_time\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1b8c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "window = 1440\n",
    "i = 0\n",
    "\n",
    "batch_data_size = len(test_data)//num_workers\n",
    "batch_data = []\n",
    "batch_data_all = []\n",
    "counter = 0\n",
    "num_worker = 0\n",
    "\n",
    "running_time = []\n",
    "total_running_time = 0.0\n",
    "\n",
    "while i< len(test_data[0])-window:\n",
    "    for arr in test_data:\n",
    "        if (counter < batch_data_size):\n",
    "            batch_data.append(arr[i:i+window])\n",
    "            counter = counter + 1\n",
    "        elif num_worker == num_workers - 1:\n",
    "            batch_data.append(arr[i:i+window])\n",
    "        else:\n",
    "            counter = 0\n",
    "            batch_data_all.append(batch_data)\n",
    "            \n",
    "            batch_data = []\n",
    "            batch_data.append(arr[i:i+window])\n",
    "            counter = counter + 1\n",
    "            num_worker = num_worker + 1\n",
    "    \n",
    "    batch_data_all.append(batch_data)\n",
    "    batch_data = []\n",
    "        \n",
    "    num_worker = 0\n",
    "    counter = 0\n",
    "    \n",
    "    running_time_temp = parallel_batch_processing_futures(loaded_model, batch_data_all)\n",
    "    running_time.append(running_time_temp)\n",
    "    total_running_time = total_running_time + running_time_temp\n",
    "    \n",
    "    batch_data_all = []\n",
    "\n",
    "    i = i + window\n",
    "\n",
    "    \n",
    "if i < len(test_data[0]):\n",
    "    for arr in test_data:\n",
    "        if (counter < batch_data_size):\n",
    "            batch_data.append(arr[i:i+window])\n",
    "            counter = counter + 1\n",
    "        elif num_worker == num_workers - 1:\n",
    "            batch_data.append(arr[i:i+window])\n",
    "        else:\n",
    "            counter = 0\n",
    "            batch_data_all.append(batch_data)\n",
    "            \n",
    "            batch_data = []\n",
    "            batch_data.append(arr[i:i+window])\n",
    "            counter = counter + 1\n",
    "            num_worker = num_worker + 1\n",
    "    \n",
    "    batch_data_all.append(batch_data_all)\n",
    "    batch_data = []\n",
    "    \n",
    "    num_worker = 0\n",
    "    counter = 0\n",
    "    \n",
    "    running_time_temp = parallel_batch_processing_futures(loaded_model, batch_data_all)\n",
    "    running_time.append(running_time_temp)\n",
    "    total_running_time = total_running_time + running_time_temp\n",
    "    \n",
    "    batch_data_all = []\n",
    "\n",
    "\n",
    "print (\"total_running_time = \", total_running_time )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37345e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_streams = 20000, window_size =  1440 :\n",
    "        \n",
    "    sequential: \n",
    "        total_running_time =  10964.847057819366\n",
    "        CPU times: user 3h 2min 42s, sys: 11 ms, total: 3h 2min 42s\n",
    "        Wall time: 3h 2min 44s\n",
    "    \n",
    "    threads = 8 :\n",
    "        total_running_time =  1282.675329208374\n",
    "        CPU times: user 2min 21s, sys: 1min 5s, total: 3min 27s\n",
    "        Wall time: 21min 22s\n",
    "    \n",
    "    threads = 16:\n",
    "        total_running_time =  723.8945622444153\n",
    "        CPU times: user 2min 40s, sys: 1min 7s, total: 3min 47s\n",
    "        Wall time: 12min 4s\n",
    "        \n",
    "    threads = 30:\n",
    "        total_running_time =  472.08199548721313\n",
    "        CPU times: user 3min 5s, sys: 50.3 s, total: 3min 55s\n",
    "        Wall time: 7min 52s\n",
    "            \n",
    "            \n",
    "threads = 30, window_size = 1440:\n",
    "    \n",
    "    n_streams = 20000 : \n",
    "        total_running_time =  472.08199548721313\n",
    "        CPU times: user 3min 5s, sys: 50.3 s, total: 3min 55s\n",
    "        Wall time: 7min 52s\n",
    "    \n",
    "    n_streams = 40000 :\n",
    "        total_running_time =  868.0069897174835\n",
    "        CPU times: user 17min 34s, sys: 2min 30s, total: 20min 4s\n",
    "        Wall time: 14min 28s\n",
    "\n",
    "    n_streams = 60000 :\n",
    "        total_running_time =  1290.3016259670258\n",
    "        CPU times: user 19min 49s, sys: 3min 45s, total: 23min 34s\n",
    "        Wall time: 21min 31s\n",
    "\n",
    "    n_streams = 80000 :\n",
    "        total_running_time =  1705.2955605983734\n",
    "        CPU times: user 20min 59s, sys: 4min 52s, total: 25min 51s\n",
    "        Wall time: 28min 26s\n",
    "            \n",
    "            \n",
    "threads = 30, n_streams = 80000 :\n",
    "    \n",
    "    window_size = 1440 : \n",
    "        total_running_time =  1705.2955605983734\n",
    "        CPU times: user 20min 59s, sys: 4min 52s, total: 25min 51s\n",
    "        Wall time: 28min 26s\n",
    "        \n",
    "    window_size = 2880 :\n",
    "        total_running_time =  1656.778636932373\n",
    "        CPU times: user 14min 4s, sys: 4min 28s, total: 18min 33s\n",
    "        Wall time: 27min 37s\n",
    "        \n",
    "    window_size = 4320 :\n",
    "        total_running_time =  1449.8256077766418\n",
    "        CPU times: user 9min 59s, sys: 3min 50s, total: 13min 50s\n",
    "        Wall time: 24min 10s\n",
    "        \n",
    "    \n",
    "    window_size =  5760 : \n",
    "        total_running_time =  1602.882644891739\n",
    "        CPU times: user 9min 41s, sys: 4min 13s, total: 13min 55s\n",
    "        Wall time: 26min 43s\n",
    "        \n",
    "       \n",
    "    window_size = 7200 :\n",
    "        total_running_time =  1603.0916907787323\n",
    "        CPU times: user 8min 46s, sys: 4min 18s, total: 13min 4s\n",
    "        Wall time: 26min 43s\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736c7077",
   "metadata": {},
   "source": [
    "## Close Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2b70f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
