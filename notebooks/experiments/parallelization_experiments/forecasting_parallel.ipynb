{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72425061",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "module_path = './'\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from modules.preprocessing import *\n",
    "from modules.io import *\n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "from timeit import default_timer as timer\n",
    "from sklearn.ensemble import RandomForestRegressor as RFRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "import lightgbm as lgb\n",
    "plt.style.use('ggplot')\n",
    "from sklearn.linear_model import QuantileRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e407f2",
   "metadata": {},
   "source": [
    "# Test the performance of forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783d665f",
   "metadata": {},
   "source": [
    "## Import Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799b1e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "from dask.distributed import wait\n",
    "import dask\n",
    "from dask import delayed\n",
    "dask.config.set(scheduler='synchronous')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8790ab4",
   "metadata": {},
   "source": [
    "## Start Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d95e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 30\n",
    "client = Client(n_workers=num_workers,threads_per_worker=1)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a444606",
   "metadata": {},
   "source": [
    "## Read filenames of datasets (streams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82750a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read filenames of datasets (streams)\n",
    "filenames = sorted(glob(os.path.join('/data/data2/forecasting_data/synthetic/','*.csv')))\n",
    "filenames = filenames[:100] # load 100 for a test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a08f27a",
   "metadata": {},
   "source": [
    "## Read datasets (streams) with associated variables from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8464129",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read datasets (streams) with associated variables\n",
    "\n",
    "test_data = []\n",
    "for f in filenames:\n",
    "    df = load_df(f)\n",
    "    \n",
    "    df = df.set_index('timestamp')\n",
    "    feats = list(set([x for x in df.columns if 'Grd_Prod_Pwr_min_(t+' not in x]))\n",
    "\n",
    "    test_data.append(df[feats].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1f94cc",
   "metadata": {},
   "source": [
    "## Create streams in memory for the experimental evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58469e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read once, create many copies\n",
    "filenames = ['/data/data2/forecasting_data/synthetic/forecasting_data0.csv'] # load 1 test file\n",
    "\n",
    "df = load_df(filenames[0])\n",
    "df = df.set_index('timestamp')\n",
    "\n",
    "feats = list(set([x for x in df.columns if 'Grd_Prod_Pwr_min_(t+' not in x]))\n",
    "temp_stream = df[feats].values\n",
    "\n",
    "n_streams = 10\n",
    "n_rows = 2\n",
    "test_data = np.tile([temp_stream], (n_streams, 1, 1))\n",
    "for j in range(len(test_data)):\n",
    "    for i in range(test_data.shape[2]):\n",
    "        noise =  np.random.normal(0, 0.1, test_data.shape[1])\n",
    "        test_data[j, :, i] = test_data[j, :, i] + noise\n",
    "len(test_data[0])     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b04bb5",
   "metadata": {},
   "source": [
    "## Read pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1a1044",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read pretrained model\n",
    "file_path = '/home/ipsarros/pretrained_models/forecasting_regressor_chain2.pickle'\n",
    "with open(file_path, 'rb') as file:\n",
    "    loaded_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c8d9f8",
   "metadata": {},
   "source": [
    "## Sequential code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87852577",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#sequential\n",
    "\n",
    "window = 40\n",
    "i = 0\n",
    "running_time = []\n",
    "total_running_time = 0.0\n",
    "\n",
    "while i< len(test_data[0])-window:\n",
    "    start = time.time()\n",
    "    for arr in test_data:\n",
    "        result = loaded_model.predict(arr[i:i+window])\n",
    "    end = time.time()\n",
    "    running_time_temp = end - start\n",
    "    running_time.append(running_time_temp)\n",
    "    total_running_time = total_running_time + running_time_temp  \n",
    "    \n",
    "    i = i + window\n",
    "    \n",
    "if i < len(test_data[0]):\n",
    "    start = time.time()\n",
    "    for arr in test_data:\n",
    "        result = loaded_model.predict(arr[i:len(test_data[0])])\n",
    "    end = time.time()\n",
    "    running_time_temp = end - start\n",
    "    running_time.append(running_time_temp)\n",
    "    total_running_time = total_running_time + running_time_temp  \n",
    "    \n",
    "print (\"total_running_time = \", total_running_time )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8645e7bd",
   "metadata": {},
   "source": [
    "## Parallel Batch code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d53fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecasting_predict (loaded_model,batch_data):\n",
    "    for batch in batch_data:\n",
    "        result = loaded_model.predict(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2936b26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_batch_processing_futures(loaded_model, batch_data):\n",
    "    running_time = 0.0\n",
    "    futures = []\n",
    "    \n",
    "    start = time.time()\n",
    "    for batch in batch_data:\n",
    "        future = client.submit(forecasting_predict,loaded_model, batch)\n",
    "        futures.append(future)\n",
    "    wait(futures, return_when=\"ALL_COMPLETED\")\n",
    "    end = time.time()\n",
    "    del futures\n",
    "    futures = []\n",
    "    \n",
    "    running_time = end - start\n",
    "    \n",
    "    return running_time\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56549aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "window = 40\n",
    "i = 0\n",
    "\n",
    "batch_data_size = len(test_data)//num_workers\n",
    "batch_data = []\n",
    "batch_data_all = []\n",
    "counter = 0;\n",
    "num_worker = 0\n",
    "\n",
    "running_time = []\n",
    "total_running_time = 0.0\n",
    "\n",
    "while i< len(test_data[0])-window:\n",
    "    for arr in test_data:\n",
    "        if (counter < batch_data_size):\n",
    "            batch_data.append(arr[i:i+window])\n",
    "            counter = counter + 1\n",
    "        elif num_worker == num_workers - 1:\n",
    "            batch_data.append(arr[i:i+window])\n",
    "        else:\n",
    "            counter = 0\n",
    "            batch_data_all.append(batch_data)\n",
    "            \n",
    "            batch_data = []\n",
    "            batch_data.append(arr[i:i+window])\n",
    "            counter = counter + 1\n",
    "            num_worker = num_worker + 1\n",
    "    \n",
    "    batch_data_all.append(batch_data)\n",
    "    batch_data = []\n",
    "      \n",
    "    num_worker = 0\n",
    "    counter = 0\n",
    "    \n",
    "    running_time_temp = parallel_batch_processing_futures(loaded_model, batch_data_all)\n",
    "    running_time.append(running_time_temp)\n",
    "    total_running_time = total_running_time + running_time_temp\n",
    "    batch_data_all = []\n",
    "\n",
    "    i = i + window\n",
    "\n",
    "if i < len(test_data[0]):\n",
    "    for arr in test_data:\n",
    "        if (counter < batch_data_size):\n",
    "            batch_data.append(arr[i:len(test_data[0])])\n",
    "            counter = counter + 1\n",
    "        elif num_worker == num_workers - 1:\n",
    "            batch_data.append(arr[i:len(test_data[0])])\n",
    "        else:\n",
    "            counter = 0\n",
    "            batch_data_all.append(batch_data)\n",
    "            \n",
    "            batch_data = []\n",
    "            batch_data.append(arr[i:len(test_data[0])])\n",
    "            counter = counter + 1\n",
    "            num_worker = num_worker + 1\n",
    "    \n",
    "    batch_data_all.append(batch_data)\n",
    "    batch_data = []\n",
    "      \n",
    "    num_worker = 0\n",
    "    counter = 0\n",
    "    \n",
    "    running_time_temp = parallel_batch_processing_futures(loaded_model, batch_data_all)\n",
    "    running_time.append(running_time_temp)\n",
    "    total_running_time = total_running_time + running_time_temp\n",
    "    batch_data_all = []\n",
    "\n",
    "print (\"total_running_time = \", total_running_time )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9e5a90",
   "metadata": {},
   "source": [
    "## Experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60301276",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_streams = 40000, threads = 30:\n",
    "\n",
    "    window_size = 20:    \n",
    "        total_running_time =  1004.4421761035919\n",
    "        CPU times: user 2h 47min 12s, sys: 3min 58s, total: 2h 51min 11s\n",
    "        Wall time: 16min 44s\n",
    "\n",
    "    window_size = 40:\n",
    "        otal_running_time =  752.8725855350494\n",
    "        CPU times: user 1h 31min 15s, sys: 2min 57s, total: 1h 34min 12s\n",
    "        Wall time: 12min 33s\n",
    "\n",
    "    window_size = 60:\n",
    "        total_running_time =  668.5420389175415\n",
    "        CPU times: user 1h 4min 57s, sys: 2min 43s, total: 1h 7min 40s\n",
    "        Wall time: 11min 8s   \n",
    "\n",
    "    window_size = 80:\n",
    "        total_running_time =  626.7318153381348\n",
    "        CPU times: user 53min 17s, sys: 2min 30s, total: 55min 48s\n",
    "        Wall time: 10min 26s\n",
    "\n",
    "    window_size = 100:\n",
    "        total_running_time =  584.7882263660431\n",
    "        CPU times: user 40min 30s, sys: 2min 24s, total: 42min 55s\n",
    "        Wall time: 9min 44s\n",
    "    \n",
    "      \n",
    "threads = 30, window_size = 40 :\n",
    "\n",
    "    n_streams = 20000 :\n",
    "        total_running_time =  434.73500967025757\n",
    "        CPU times: user 1h 28min 55s, sys: 1min 42s, total: 1h 30min 37s\n",
    "        Wall time: 7min 14s\n",
    "\n",
    "    n_streams = 40000 :\n",
    "        total_running_time =  752.8725855350494\n",
    "        CPU times: user 1h 31min 15s, sys: 2min 57s, total: 1h 34min 12s\n",
    "        Wall time: 12min 33s   \n",
    "\n",
    "    n_streams = 60000 :\n",
    "        total_running_time =  1034.7841057777405\n",
    "        CPU times: user 1h 32min 20s, sys: 4min 10s, total: 1h 36min 30s\n",
    "        Wall time: 17min 15s   \n",
    "\n",
    "    n_streams = 80000 :\n",
    "        total_running_time =  1337.0246572494507\n",
    "        CPU times: user 1h 34min 2s, sys: 4min 58s, total: 1h 39min 1s\n",
    "        Wall time: 22min 17s \n",
    "\n",
    "    n_streams = 100000 :\n",
    "        total_running_time =  1653.3374433517456\n",
    "        CPU times: user 1h 35min 54s, sys: 6min 27s, total: 1h 42min 21s\n",
    "        Wall time: 27min 34s\n",
    "\n",
    "    n_streams = 120000 :\n",
    "        total_running_time =  1994.925544500351\n",
    "        CPU times: user 1h 36min 28s, sys: 7min 3s, total: 1h 43min 32s\n",
    "        Wall time: 33min 16s\n",
    "    \n",
    "    \n",
    "n_streams = 60000,  window_size = 40:\n",
    "\n",
    "    sequential :\n",
    "        total_running_time =  20934.46885061264\n",
    "        CPU times: user 5h 48min 25s, sys: 10.5 s, total: 5h 48min 36s\n",
    "        Wall time: 5h 48min 54s\n",
    "\n",
    "    threads = 8 :\n",
    "        total_running_time =  2735.172491312027\n",
    "        CPU times: user 5min 9s, sys: 3min 30s, total: 8min 40s\n",
    "        Wall time: 45min 35s\n",
    "\n",
    "    threads = 16 :\n",
    "        total_running_time =  1562.24662899971\n",
    "        CPU times: user 5min 51s, sys: 3min 11s, total: 9min 3s\n",
    "        Wall time: 26min 2s\n",
    "\n",
    "    threads = 30 :\n",
    "        total_running_time =  1034.7841057777405\n",
    "        CPU times: user 1h 32min 20s, sys: 4min 10s, total: 1h 36min 30s\n",
    "        Wall time: 17min 15s  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070afa57",
   "metadata": {},
   "source": [
    "## Close Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34047b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
