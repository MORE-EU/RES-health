{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae35ddb6",
   "metadata": {},
   "source": [
    "# Underperformance detection\n",
    "\n",
    "In this notebook, we explore a self-supervised approach for the underperformance use-case. Given a time series comprising measurements from a turbine including power output and dependent parameters like wind speed and rotor speed, we i) distinguish between periods of underperformance and periods of optimal performance using an unsupervised method, and ii) we use those periods to train a classifier which can be then tested in new data.\n",
    "\n",
    "To evaluate our approach, we compare our output with the ground-truth information, where we assume that we have underperformance if and only if the static yaw angle (which is provided) is non-zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc414e59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "module_path = './'\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from modules.preprocessing import *\n",
    "from modules.io import *\n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "from timeit import default_timer as timer\n",
    "from sklearn.ensemble import RandomForestRegressor as RFRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "import lightgbm as lgb\n",
    "plt.style.use('ggplot')\n",
    "from sklearn.linear_model import QuantileRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2f86f7",
   "metadata": {},
   "source": [
    "# Test the performance of Underperformance detection for big data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebb787d",
   "metadata": {},
   "source": [
    "## Import Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18b6666",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "from dask.distributed import wait\n",
    "import dask\n",
    "from dask import delayed\n",
    "dask.config.set(scheduler='synchronous')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdc0991",
   "metadata": {},
   "source": [
    "## Start Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6314ce1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 30\n",
    "client = Client(n_workers=num_workers,threads_per_worker=1)\n",
    "#client = Client(n_workers=1,threads_per_worker=num_workers)\n",
    "\n",
    "#client = Client(n_workers=1,threads_per_worker=30)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fd5dfb",
   "metadata": {},
   "source": [
    "## Read and create files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24330305",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = ['active power', 'wind speed',  'rotor speed']\n",
    "\n",
    "#parameters: \n",
    "n_streams = 600000\n",
    "window_size = 1000\n",
    "n_iter = 30 \n",
    "\n",
    "# must: n_windows < len(filenames)\n",
    "temp_stream = pd.read_csv('/data/data1/synthetic_yaw_data/testing_set0.csv', nrows = window_size)[feats].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f68654",
   "metadata": {},
   "source": [
    "## Read pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce19e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read pretrained model\n",
    "file_path = '/home/ipsarros/pretrained_models/underperformance_classifier2.pickle'\n",
    "\n",
    "with open(file_path, 'rb') as file:\n",
    "    loaded_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6638261",
   "metadata": {},
   "source": [
    "## Sequential code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c5dfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_running_time = 0\n",
    "for i in range(n_iter):\n",
    "    #create new data of size window_size\n",
    "    test_data = np.tile([temp_stream], (n_streams, 1, 1))\n",
    "    for j in range(len(test_data)):\n",
    "        for i in range(test_data.shape[2]):\n",
    "            noise =  np.random.normal(0, 0.1, test_data.shape[1])\n",
    "            test_data[j, :, i] = test_data[j, :, i] + noise\n",
    "            \n",
    "    #make predictions for all new data\n",
    "    for arr in test_data:\n",
    "        start = time.time()\n",
    "        result = loaded_model.predict(arr, num_threads=1)\n",
    "        end = time.time()\n",
    "        running_time_temp = end - start\n",
    "        total_running_time = total_running_time + running_time_temp  \n",
    "    \n",
    "    \n",
    "print (\"total_running_time = \", total_running_time )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63870d6",
   "metadata": {},
   "source": [
    "## Parallel Batch code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0722cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def underperformance_predict(loaded_model,batch_data):\n",
    "    #results = []\n",
    "    for batch in batch_data:\n",
    "        result = loaded_model.predict(batch,num_threads=1)\n",
    "        #print(result)\n",
    "     #   results.append(result)\n",
    "    #return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfbc891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_batch_processing_futures(loaded_model, batch_data):\n",
    "    running_time = 0.0\n",
    "    futures = []\n",
    "    \n",
    "    start = time.time()\n",
    "    for batch in batch_data:\n",
    "        future = client.submit(underperformance_predict,loaded_model, batch)\n",
    "        futures.append(future)\n",
    "    \n",
    "    #client.gather(futures)\n",
    "    #print (results)\n",
    "    wait(futures, return_when=\"ALL_COMPLETED\")\n",
    "    #wait(futures)\n",
    "    #counter = 0\n",
    "   # for future, result in as_completed(futures, with_results=True):\n",
    "        #print(\"size = \",len(result))\n",
    "    #    counter = counter + len (result)\n",
    "    #    print(\"result = \", result)\n",
    "    \n",
    "    #print (\"counter = \" , counter)\n",
    "    end = time.time()\n",
    "    del futures\n",
    "    futures = []\n",
    "    \n",
    "    running_time = end - start\n",
    "    \n",
    "    return running_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70966068",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#new code to do\n",
    "total_running_time = 0\n",
    "for i in range(n_iter):\n",
    "    #create new data of size window_size\n",
    "    test_data = np.tile([temp_stream], (n_streams, 1, 1))\n",
    "    for j in range(len(test_data)):\n",
    "        for i in range(test_data.shape[2]):\n",
    "            noise =  np.random.normal(0, 0.1, test_data.shape[1])\n",
    "            test_data[j, :, i] = test_data[j, :, i] + noise\n",
    "    \n",
    "    batch_data_size = len(test_data)//num_workers\n",
    "    batch_data = []\n",
    "    batch_data_all = []\n",
    "    counter = 0\n",
    "    num_worker = 0\n",
    "    \n",
    "    #make predictions for all new data\n",
    "    for arr in test_data:\n",
    "        if (counter < batch_data_size):\n",
    "            batch_data.append(arr)\n",
    "            counter = counter + 1\n",
    "        elif num_worker == num_workers - 1:\n",
    "            batch_data.append(arr)\n",
    "        else:\n",
    "            counter = 0\n",
    "            batch_data_all.append(batch_data)\n",
    "            \n",
    "            batch_data = []\n",
    "            batch_data.append(arr)\n",
    "            counter = counter + 1\n",
    "            num_worker = num_worker + 1\n",
    "    \n",
    "    batch_data_all.append(batch_data)\n",
    "    batch_data = []\n",
    "    \n",
    "    num_worker = 0\n",
    "    counter = 0\n",
    "    \n",
    "    running_time_temp = parallel_batch_processing_futures(loaded_model, batch_data_all)\n",
    "    #running_time.append(running_time_temp)\n",
    "    total_running_time = total_running_time + running_time_temp\n",
    "    \n",
    "    batch_data_all = []\n",
    "   \n",
    "    \n",
    "print (\"total_running_time = \", total_running_time )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bbf881",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92898589",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments \n",
    "\n",
    "n_streams = 600000, window_size = 1000, n_iterations = 10, threads = 30:\n",
    "    \n",
    "    total_running_time =  3953.3994550704956\n",
    "    CPU times: user 33min 29s, sys: 11min 31s, total: 45min\n",
    "    Wall time: 1h 15min 21s\n",
    "\n",
    "\n",
    "n_streams = 600000, window_size = 1000, n_iterations = 20, threads = 30:\n",
    "    \n",
    "    total_running_time =  7809.9085302352905\n",
    "    CPU times: user 1h 4min 23s, sys: 23min 32s, total: 1h 27min 55s\n",
    "    Wall time: 2h 28min 39s\n",
    "    \n",
    "    \n",
    "n_streams = 600000, window_size = 1000, n_iterations = 30, threads = 30:\n",
    "\n",
    "    total_running_time =  11975.88755440712\n",
    "    CPU times: user 1h 33min, sys: 37min 8s, total: 2h 10min 9s\n",
    "    Wall time: 3h 47min 21s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7544139e",
   "metadata": {},
   "source": [
    "## Close Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb4f2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6930f02a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
